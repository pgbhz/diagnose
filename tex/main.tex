        \documentclass[a4paper,12pt]{article}
    \usepackage[a4paper,margin=1in]{geometry}
    \usepackage{graphicx}
    \usepackage{amsmath, amssymb}
    \usepackage{hyperref}
    \usepackage{array}
    \usepackage{caption}
    \usepackage{listings}
    \usepackage{subfig}
    \usepackage{enumitem}
    \usepackage[style=ieee, backend=biber]{biblatex}
    \addbibresource{references.bib}
    
    \title{Multimodal Synthesis of Clinical Text and Imagery for Automated Triage in Oral Pathology}
    
    \author{
    Pedro Gabriel Amorim Soares$^{1}$ \\
    $^{1}$PUC Minas, Brazil \\
    \small{pedrogabrielbhz@gmail.com}
    }
    \date{\today}
    
    \begin{document}
    \maketitle
    
    \begin{abstract}
    This research project proposes a multimodal framework for the automated triage of oral health conditions, addressing the issue of diagnostic delays in resource-constrained healthcare systems. The methodology integrates patient-reported data and intraoral photographs. A late-fusion mechanism synthesizes outputs from LLM and multimodal augmentations to generate a unified clinical urgency score. This process operates within a message-driven architecture for high-throughput and asynchronous augmentations of initial input data. The primary objective is to enhance triage accuracy and substantially reduce diagnostic latency for critical pathologies. This work aims to contribute with an architectural blueprint and a methodological approach for applying multimodal machine learning models to clinical triage in public health settings, furthering efficient and equitable patient care.
    
    \end{abstract}
    
    \section{Introduction}
    Oral diseases constitute a major global health burden, affecting an estimated 3.5 billion people worldwide. In Brazil, this challenge is compounded by significant regional disparities in access to specialized oral healthcare. Despite having a high number of dental professionals per capita, their distribution is heavily concentrated in the Southeast region, leaving many areas in the North and Northeast critically underserved. This inequity results in extensive waiting lists within the public health system (SUS), where specialist consultations can be delayed for several months. Such delays are particularly detrimental for the prognosis of time-sensitive conditions, including oral squamous cell carcinoma, for which Brazil's National Cancer Institute (INCA) estimates thousands of new cases annually \cite{INCA2025}.
    
    The integration of machine learning in healthcare has demonstrated remarkable potential for improving diagnostic accuracy and speeding up clinical triage \cite{Chen}. In dentistry, deep learning models have shown high precision and recall in tasks such as the detection of oral cancer from clinical images \cite{Khanagar2021}. More recent advances in multimodal models, which synthesizes information from a diverse set of data types such as clinical text and images, introduce opportunities for automated and highly available patient assessment. However, the application of such technologies to the specific problem of oral health triage remains underexplored, particularly regarding the development of integrated systems that can process both clinical questionnaires and visual examination data in tandem.
    
    To address this gap, this research proposes a novel multimodal system designed for oral health triage. The system combines Large Language Models (LLMs) for the semantic processing of patient history and symptoms with computer vision models for the analysis of intraoral images. This approach is implemented within a distributed, message-driven architecture to ensure scalability and to enable priority-based routing, thereby optimizing patient care.
    
    \section{Literature Review}
    
    Traditional approaches to oral disease detection have relied primarily on visual examination and manual screening. Recent studies have demonstrated the effectiveness of deep learning models in detecting oral cancer \cite{Chen}. Convolutional Neural Networks (CNNs) have been particularly successful in identifying malignant lesions, with architectures such as ResNet and EfficientNet showing promising results \cite{Javed2020}. 
    
    The application of artificial intelligence has expanded across various dental imaging tasks \cite{Lee2021}, with recent work exploring the use of transformer-based models for enhanced diagnostic capabilities \cite{Beneng2023}. Convolutional Neural Networks \cite{oshea2015introductionconvolutionalneuralnetworks} (CNNs) and Support Vector Machines (SVMs) are prominent in image classification. CNNs learn hierarchical features through convolutional layers, pooling, and activation functions, enabling end-to-end learning from raw pixels. The convolution operation is defined as:
    $$
    (f * g)(i,j) = \sum_m \sum_n f(m,n) g(i-m, j-n)
    $$
    where $f$ is the input image and $g$ is the kernel. Max-pooling reduces spatial dimensions by selecting the maximum value in a window, providing translation invariance. SVMs, conversely, map data to a higher-dimensional space via kernels for linear separability. The RBF kernel computes similarity as:
    $$
    K(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2\right)
    $$
    where $\gamma$ controls the kernel width. While SVMs excel in small datasets with explicit feature engineering, CNNs outperform in large-scale image tasks due to automatic feature extraction. Studies show CNNs achieving higher accuracy in oral cancer detection compared to SVMs, attributed to their ability to capture spatial hierarchies \cite{Javed2020}. Concurrently, the emergence of Large Language Models (LLMs) has enabled natural language processing in medical contexts. Models like GPT-4 and specialized medical variants such as Med-PaLM have demonstrated capabilities in clinical reasoning, symptom assessment, and treatment recommendation, often exceeding those of specialists \cite{khanagar2021developments}. A systematic review of these models highlights their potential across various clinical tasks, while also noting challenges related to evaluation and bias \cite{Li2024}. However, their application in structured triage systems, particularly for oral health, remains underexplored, despite their growing consideration in clinical practice \cite{Thirunavukarasu2023}. 
    
    To build a comprehensive diagnostic system, multimodal fusion techniques combine different data types to improve diagnostic accuracy \cite{Acosta2022}. Recent surveys on multimodal learning highlight the promise of Vision-Language models, where textual and visual data are integrated to provide a contextualized assessment \cite{Zhang2023}. Finally, the implementation of such a system requires a robust and scalable backend. Distributed systems in healthcare must balance scalability, reliability, and compliance with data protection regulations. Architectures based on message queues, such as RabbitMQ or Kafka \cite{python2024}, provide the asynchronous processing capabilities essential for handling variable loads in clinical settings and ensuring interoperability, often guided by standards like HL7 FHIR. Chatbots are often reliable sources of primary clinical input, being highly available and accessible. Considering these data sources, the abundance of open-source models, and cheap compute, a solution combining these components may democratize access to fast clinical diagnoses.
    
    \section{Motivation}
    
    The Brazilian public health system (SUS) provides a relatively high number of dental professionals per capita, but endemic structural barriers create profound inequities in healthcare access. This inefficiency is most starkly illustrated by the severe geographic maldistribution of expertise. Data from the Federal Council of Dentistry (CFO) reveals that over 50\% of dentists are concentrated in the Southeast region, serving just 42\% of the population, leaving vast territories critically underserved \cite{CFO2024}. The direct consequence is long waiting periods for specialist consultations, which frequently exceed months. For time-sensitive pathologies such as oral squamous cell carcinoma—for which Brazil's National Cancer Institute (INCA) projects over 15,000 new cases annually—such delays are not a matter of inconvenience, but a primary determinant of prognosis, contributing to a 5-year survival rate below 50\% for advanced-stage diagnoses \cite{INCA2025}.
    
    This project aims to engineer an intelligent framework that can overcome these barriers in a semi automated manner, concurrently synthesizing clinical and image data. By engineering a scalable architecture to enhance early diagnosis and stratify patients by clinical urgency, this work contributes an architectural blueprint for mitigating diagnostic latency in other resource-constrained health systems. It directly aligns with the United Nations' Sustainable Development Goal 3, which mandates a reduction in premature mortality from non-communicable diseases and the advancement of equitable access to essential health services \cite{UNSDG3}.
    
    \section{Problem Statement and Objectives}
    
    \subsection{Problem Statement}
    
    The prevailing paradigm for oral health triage in Brazilian public healthcare facilities is characterized by manual assessment, often conducted by non-specialist or ill-advised practitioners. This reliance on subjective evaluation results in inconsistent prioritization of urgent cases, delayed diagnosis of critical pathologies, and inefficient allocation of scarce specialist resources. The current process lacks the formal structure, objectivity, and scalability required to manage patient care effectively in resource-constrained environments.
    
    This work addresses a fundamental question in AI-assisted medical triage: how can different computational models—ranging from specialized vision classifiers to general-purpose multimodal AI—be effectively assessed, combined, and deployed to support clinical decision-making? The investigation is structured around three interconnected research challenges:
    
    \textbf{First-line classification performance:} We investigate which models provide the most accurate and efficient initial assessment for binary oral cancer detection. This involves comparative evaluation of specialized models (SVM, CNN) against general-purpose AI (Gemini) across metrics of accuracy, inference speed, and robustness. The goal is to identify optimal architectures for real-time, front-line screening where milliseconds matter and computational resources are constrained.
    
    \textbf{Generative AI for hypothesis augmentation:} Beyond binary classification, we explore how large language models can augment initial triage by generating differential diagnoses, enumerating testable hypotheses, and identifying gaps in clinical information. This capability enables the system to dynamically request additional patient data—symptoms, history, or supplementary images—to validate or refute diagnostic hypotheses, mimicking the iterative reasoning process of clinical specialists.
    
    \textbf{Multimodal fusion and system reliability:} We examine architectural strategies for integrating vision-based classifiers with language models to leverage their complementary strengths. This includes late-fusion mechanisms, where independent model outputs are synthesized, and exploration of how to engineer a production-grade system that ensures reliability, auditability, and safety for field deployment in public health settings.
    
    Formally, we define the triage task as learning a mapping function:
    $$ T: (\mathcal{Q} \times \mathcal{I}) \rightarrow (\mathcal{P}, \mathcal{H}, \mathcal{R}) $$
    where $\mathcal{Q}$ represents structured questionnaire data, $\mathcal{I}$ is the space of intraoral images, $\mathcal{P}$ is the set of priority classes, $\mathcal{H}$ denotes generated hypotheses, and $\mathcal{R}$ specifies requests for additional information. This formulation extends traditional classification to encompass the full decision-support workflow required for clinical triage.
    
    Therefore, the core research question is: \textit{How can specialized vision models and general-purpose multimodal AI be systematically evaluated, architecturally integrated, and reliably deployed to create an effective, scalable oral health triage system suitable for field validation and clinical use?}
    
    \subsection{Objectives}
    
    To design, implement, and evaluate a clinically viable, multimodal artificial intelligence system for the triage of oral health conditions. The system will integrate natural language processing of patient histories with computer vision analysis of intraoral images within a distributed, message-driven architecture designed to reduce diagnostic latency and enhance patient prioritization.
    
    \section{Methodology}
    The system will be developed as a set of modular services. The workflow follows three main stages: data collection, automated analysis, and specialist review. The data collection stage is handled through a chatbot available on platforms such as WhatsApp or Telegram. Patients or health professionals will submit clinical information and intraoral photographs. A schema-versioned questionnaire, defined in JSON Schema, ensures that data collection remains consistent even when the protocol evolves. Submissions are stored and forwarded to a message queue system, which manages asynchronous processing and prioritization of cases. The queue enables urgent cases to be analyzed with lower latency and supports reprioritization when needed. The automated analysis stage combines natural language processing and computer vision models. Textual data, such as symptoms and history, will be processed by pretrained biomedical language models adapted to Portuguese. Visual data, consisting of intraoral photographs, will be analyzed using deep learning models trained to detect caries, inflammation, and other oral pathologies. The outputs are then fused into a unified representation. A classification layer converts this information into a discrete priority level (e.g., emergency, urgent, or routine). The specialist interface is a web-based dashboard that displays the collected data, AI-generated pre-diagnosis, and triage priority. It also allows professionals to override the automated decision when necessary, ensuring human supervision. The implementation will follow an iterative development process. Early cycles will focus on chatbot functionality and backend integration. Subsequent cycles will add machine learning components, multimodal fusion, and finally the specialist dashboard. Continuous testing and feedback from clinicians will guide refinements to usability, accuracy, and reliability.
    
    \subsection{Machine Learning Prototype for Image Classification}
    To validate the computer vision component, a prototype was developed for binary classification of oral cancer from intraoral images. The dataset comprises approximately 950 training images (500 cancer, 450 non-cancer) and 131 validation images (87 cancer, 44 non-cancer), sourced from public Kaggle repositories \cite{zaidpy2023,shivam172992023}. Images were resized to 128×128 pixels and standardized via normalization (division by 255) and mean subtraction to center pixel values around zero, mitigating gradient issues in optimization.
    
    Two models were evaluated: a Support Vector Machine (SVM) with RBF kernel and a Convolutional Neural Network (CNN). The SVM operates on flattened 49,152-dimensional feature vectors, while the CNN processes 128×128×3 tensors through convolutional layers (32 and 64 filters, 3×3 kernels, ReLU activation), max-pooling (2×2), and dense layers with dropout (0.5). Training used binary cross-entropy loss and Adam optimizer for 10 epochs.
    
    \section{Implementations, Tests, and Preliminary Results}
    
    The interectable system is currently implemented in two main components: (i) a conversational interface integrated with Telegram, and (ii) a web application that provides data storage, case visualization, and specialist access. The Telegram bot was developed by directly interfacing with the Telegram API via HTTP requests in Golang. It manages multi-step conversations, collects answers to structured questionnaires, and receives intraoral images from users. Collected data is submitted to the backend through authenticated REST endpoints.

    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/cb1.png}
        \caption{An example of chatbot conversation, Telegram.}
    \end{figure}

    The backend was implemented with Golang and extended with a lightweight API layer that exposes endpoints for questionnaire retrieval, image upload, and submission of answers. All submissions are stored in JSON format, with images saved in a dedicated upload directory. A web dashboard was designed to allow specialists to review cases, including patient answers, uploaded images, and AI analysis placeholders. Authentication mechanisms were added to restrict access to authorized users.

    The frontend is composed of an Angular app. Testing was conducted in iterative cycles. At the unit level, conversation flows were verified with test users in Telegram, ensuring that authentication, question progression, and photo uploads functioned correctly. At the integration level, API calls between the bot and the Golang backend were validated using real data, with emphasis on image transfer and JSON payloads. The web dashboard was tested manually to confirm that submitted data is correctly rendered and images are accessible. Automated tests with Cypress are also implemented.
    
    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/dash2.png}
        \caption{Sample screen for pre-diagnosis augmentation generated by the LLM component.}
    \end{figure}
    
    The system supports multiple simultaneous sessions, preserves conversational context, and successfully handles the upload of several images per case. In practice runs with simulated data, the average submission (three answers and up to five images) was completed in under two minutes. These results suggest that the architecture is functional and provides a suitable foundation for the next stage, which will involve integrating AI models for text and image analysis and conducting pilot studies with healthcare professionals. Considering the different vision models  an assesment of performance is made below.
      
    \subsubsection{Model assesment for imagery}
    
    Two models were evaluated, a Support Vector Machine (SVM) with RBF kernel and a Convolutional Neural Network (CNN). The SVM operates on flattened 49,152-dimensional feature vectors, while the CNN processes 128×128×3 tensors through convolutional layers (32 and 64 filters, 3×3 kernels, ReLU activation), max-pooling (2×2), and dense layers with dropout (0.5). Training used binary cross-entropy loss and Adam optimizer for 10 epochs.
    
    Evaluations on test (190 images) and validation sets revealed CNN superiority: 84.21\% vs. 82.11\% accuracy on test, and 74.81\% vs. 72.52\% on validation. Inference time favored CNN (0.41 s vs. 7.80 s for 131 images), attributed to hierarchical feature learning and optimized computations. Visualizations include confusion matrices, ROC curves, precision-recall plots, and training histories, demonstrating effective convergence without overfitting.
    
    To benchmark against general-purpose AI, a sample of 30 images from the test set was evaluated using Google's Gemini 1.5 Pro model. The model was prompted to classify images as showing oral cancer or not, with binary responses. Results showed SVM achieving 96.67\% accuracy, CNN 86.67\%, and Gemini 63.33\% on this sample. This underscores the advantage of specialized, trained models over general AI in medical image classification tasks.
    
    \begin{table}[h]
        \centering
        \caption{Classification Times for SVM and CNN on Validation Set (131 Images)}
        \label{tab:classification_times}
        \begin{tabular}{|c|c|c|}
            \hline
            Model & Time (seconds) & Relative Speed \\
            \hline
            SVM & 7.80 & 1x \\
            CNN & 0.41 & 19x faster \\
            \hline
        \end{tabular}
    \end{table}
    
    The CNN's efficiency makes it suitable for real-time applications, processing images in milliseconds compared to seconds for SVM, due to vectorized operations and learned representations reducing computational complexity.
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/svm_confusion_matrix.png}
        \caption{Confusion matrix for SVM model on test set.}
    \end{figure}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/cnn_confusion_matrix.png}
        \caption{Confusion matrix for CNN model on test set.}
    \end{figure}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{plots/roc_curve.png}
        \caption{ROC curves with AUC scores for SVM and CNN.}
    \end{figure}
    
    \begin{figure}[h]
        \centering
        \subfloat[Precision-Recall Curve]{\includegraphics[width=0.45\textwidth]{plots/precision_recall_curve.png}}
        \hfill
        \subfloat[Class Distribution]{\includegraphics[width=0.45\textwidth]{plots/class_distribution.png}}
        \caption{Precision-recall curves and class distribution in dataset.}
    \end{figure}
    
    \begin{figure}[h]
        \centering
        \subfloat[CNN Training Curves]{\includegraphics[width=0.45\textwidth]{plots/cnn_training_curves.png}}
        \hfill
        \subfloat[Prediction Probabilities]{\includegraphics[width=0.45\textwidth]{plots/prediction_probabilities.png}}
        \caption{CNN training history and prediction probability distributions.}
    \end{figure}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/model_comparison_gemini.png}
        \caption{Accuracy comparison of SVM, CNN, and Gemini on 30 sample images.}
    \end{figure}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/gemini_confusion_matrix.png}
        \caption{Confusion matrix for Gemini model on 30 sample images.}
    \end{figure}
    
    \printbibliography
    
    \end{document}